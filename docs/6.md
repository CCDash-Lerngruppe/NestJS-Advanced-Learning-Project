# Lernmaterial: Woche 6 - Mikroservices, Skalierung & Performance mit NestJS

## Lernziele

- **Mikroservice-Architektur verstehen**: Du lernst, wann und warum du eine Anwendung in mehrere unabhängige Dienste aufteilst, und welche Vorteile das für Skalierbarkeit, Fehlertoleranz und Wartbarkeit bringt.
- **NestJS-Mikroservices umsetzen**: Du erfährst, wie du mit NestJS eigene Mikroservices erstellst, die über Nachrichten (Message Broker wie RabbitMQ, Kafka oder Redis) oder einfache TCP-Verbindungen kommunizieren.
- **Caching & Performance**: Du lernst, wie du Caching (z. B. Redis) in NestJS integrierst, um die Performance und Reaktionszeiten deiner Anwendung zu verbessern.
- **Best Practices für Produktion**: Du erhältst einen Überblick über Logging, Monitoring, Health Checks und Strategien für den sicheren und zuverlässigen Betrieb deiner Anwendung.

---

## Theoretischer Teil

### Einführung in Mikroservices

**Was sind Mikroservices?**
Mikroservices sind kleine, in sich geschlossene Dienste, die jeweils für einen klar abgegrenzten Funktionsbereich verantwortlich sind. Statt einer monolithischen App, in der alle Funktionen eng verbunden sind, stehen verschiedene Dienste nebeneinander, die über klare Schnittstellen (z. B. Nachrichtenqueues, HTTP, gRPC) miteinander kommunizieren.

**Vorteile:**

- **Skalierbarkeit**: Jeder Dienst kann unabhängig hochskaliert werden.  
- **Resilienz**: Ein Ausfall eines Dienstes legt nicht zwingend das gesamte System lahm.  
- **Unabhängige Entwicklung**: Teams können getrennt an unterschiedlichen Diensten arbeiten.

### NestJS und Mikroservices

NestJS unterstützt die Entwicklung von Mikroservices mit einem speziellen Mikroservice-Modul. Statt HTTP-Requests können Dienste über Messaging-Protokolle oder andere Transport-Mechanismen miteinander kommunizieren.

**Grundlegendes Beispiel:**

```typescript
// main.ts für einen Mikroservice, der z. B. RabbitMQ als Transport nutzt
import { NestFactory } from '@nestjs/core';
import { MicroserviceOptions, Transport } from '@nestjs/microservices';
import { AppModule } from './app.module';

async function bootstrap() {
  const app = await NestFactory.createMicroservice<MicroserviceOptions>(
    AppModule,
    {
      transport: Transport.RMQ,
      options: {
        urls: ['amqp://localhost:5672'],
        queue: 'books_queue',
        queueOptions: { durable: false },
      },
    },
  );
  await app.listen();
}
bootstrap();
```

**Pattern für Kommunikation:**

- **Request/Response**: Ein Dienst fragt einen anderen Dienst an und wartet auf eine Antwort.
- **Event-driven**: Ein Dienst sendet ein Ereignis (Event) aus, ohne zu wissen, wer es empfängt (z. B. "user_created"), andere Dienste reagieren darauf.

---

### Caching & Performance

**Warum Caching?**
Caching reduziert die Last auf Datenbanken oder externe Dienste. Häufig abgefragte Daten können im Speicher gehalten werden, um die Antwortzeiten deutlich zu verkürzen.

**Redis-Integration:**
Installiere den Redis-Client:

```bash
npm install redis @nestjs/cache-manager
```

Nutze dann `CacheModule` in deinem AppModule:

```typescript
import { CacheModule, Module } from '@nestjs/common';
import { RedisClientOptions } from 'redis';

@Module({
  imports: [
    CacheModule.register<RedisClientOptions>({
      store: 'redis',
      url: 'redis://localhost:6379',
      ttl: 300, // Zeit in Sekunden
    }),
  ],
})
export class AppModule {}
```

**Verwendung im Code:**

```typescript
import { CacheInterceptor, UseInterceptors } from '@nestjs/common';

@Controller('books')
@UseInterceptors(CacheInterceptor)
export class BooksController {
  @Get()
  findAll() {
    // Das Ergebnis dieser Methode wird gecached
    return this.booksService.findAll();
  }
}
```

---

### Best Practices für Produktion

1. **Logging & Monitoring**:  
   - Verwende Logger (z. B. `@nestjs/common` Logger oder Winston) und leite Logs an einen zentralen Dienst weiter.  
   - Nutze Monitoring-Lösungen wie Prometheus+Grafana oder ELK-Stack (Elasticsearch, Logstash, Kibana).

2. **Health Checks & Readiness Probes**:  
   - Stelle Endpunkte bereit, die den Zustand des Dienstes prüfen (`GET /health`), um automatisiertes Monitoring und Load Balancer-Checks zu ermöglichen.

3. **Load Balancing & Skalierung**:  
   - Setze Load Balancer (z. B. Nginx, HAProxy) vor deine Dienste, um Lasten zu verteilen.  
   - Nutze Container-Orchestratoren wie Kubernetes, um Dienste dynamisch zu skalieren.

4. **Security in Produktion**:  
   - Sichere Secrets (Datenbank-Passwörter, JWT-Secrets) über sichere Speicherdienste (Vault, AWS Secrets Manager).  
   - Nutze TLS/SSL für sichere Datenübertragung.

---

## Praktischer Teil

1. **Einfachen Mikroservice erstellen**:  
   - Erzeuge ein neues NestJS-Projekt für einen Mikroservice, der z. B. Benachrichtigungen verschickt.
   - Implementiere einen Listener, der auf ein `user_created` Event reagiert, das von deinem Haupt-Backend (Monolith oder anderer Mikroservice) ausgesandt wird.
   - Teste die Kommunikation, indem du aus deiner Hauptanwendung per `client.emit('user_created', { userId: 1 })` das Event sendest.

2. **Caching integrieren**:  
   - Implementiere Caching für deine `findAll`-Methode im `BooksService`.
   - Rufe die Methode wiederholt auf und überprüfe, ob nur beim ersten Aufruf eine Datenbankabfrage erfolgt und anschließend der Cache gegriffen wird (du kannst das durch Logging oder Debugging verifizieren).

3. **Health Checks**:  
   - Implementiere einen `/health`-Endpunkt, der z. B. prüft, ob die Datenbankverbindung besteht.
   - Füge diesen Endpunkt zu deiner Docker- oder Kubernetes-Konfiguration als Liveness- oder Readiness-Probe hinzu.

4. **Optimierung & Skalierung (konzeptionell)**:  
   - Überlege dir, wie du deine Anwendung horizontal skalieren würdest (z. B. mehrere Instanzen deines Books-Services hinter einem Load Balancer).
   - Dokumentiere deine Strategie zur Trennung der Dienste und wähle ein Messaging-System (z. B. RabbitMQ), um Daten zwischen den Diensten auszutauschen.
   - Plane, welche Teile deiner Applikation von Mikroservices profitieren würden (z. B. Payment-Service, Notification-Service).

---

## Zusammenfassung

In dieser Woche hast du gelernt:

- Die Grundlagen von Mikroservice-Architekturen und wie du sie mit NestJS umsetzt.
- Wie du Caching nutzt, um die Performance zu steigern.
- Welche Best Practices im produktiven Einsatz von NestJS wichtig sind, von Logging über Health Checks bis hin zur Skalierung.
- Wie du deine Anwendung schrittweise in verteilte, skalierbare und robuste Systeme umwandelst.

---

## Weiterführende Ressourcen (fakultativ)

- [NestJS – Microservices](https://docs.nestjs.com/microservices/basics)
- [NestJS – Caching](https://docs.nestjs.com/techniques/caching)
- [Kafka, RabbitMQ und andere Message Broker](https://www.rabbitmq.com/tutorials/)
- [Best Practices für Produktion (NestJS Blog)](https://blog.nestjs.com/)

Diese Ressourcen helfen dir, dein Wissen weiter zu vertiefen und auf komplexere Architekturen auszudehnen.

---

Mit diesem Material verfügst du nun über ein solides Fundament, um NestJS in größeren, professionellen Setups einzusetzen und anspruchsvolle Anforderungen in Bezug auf Skalierbarkeit, Performance und Zuverlässigkeit zu erfüllen.
